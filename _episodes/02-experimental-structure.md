---
title: "Essential Features of a Comparative Experiment"
teaching: 0
exercises: 0
questions:
- "How are comparative experiments structured?"
objectives:
- "Describe the common features of comparative experiments."
keypoints:
- "The raw ingredients of comparative experiments are experimental units, treatments and responses."
source: Rmd
---



The [Generation 100 study](https://bmjopen.bmj.com/content/5/2/e007519) 
evaluated the effects of exercise on more than 1500 elderly Norwegians to 
determine if exercise led to a longer active and healthy life. Specifically the 
researchers investigated the relationship between exercise intensity and health 
and longevity. One group performed high-intensity interval training (10 minute 
warm-up followed by four 4-minute intervals at ∼90% of peak heart rate) twice a 
week for five years. A second group performed moderate exercise twice a week (50 
minutes of continuous exercise at ∼70% of peak heart rate). A third control 
group followed physical activity advice according to national recommendations. 
Clinical examinations and questionnaires were administered to all at the start 
and after one, three, and five years. Heart rate, blood pressure, leg and grip 
strength, cognitive function, and other health indicators were measured during 
clinical exams.

> ## Challenge 1: Raw ingredients of a comparative experiment
>
> Discuss the following questions with your partner, then share your answers
> to each question in the collaborative document.
>
> 1. What is the research question in this study? If you prefer to name a 
> hypothesis, turn the research question into a declarative statement.  
> 2. What are the treatments?  
> 3. What are the experimental units (the entities to which treatments are 
> applied)?  
> 4. What are the responses (the measurements used to determine treatment 
> effects)?  
> 5. Should participants have been allowed to choose which group 
> (high-intensity, moderate exercise, or national standard) they wanted to 
> join? Why or why not? Should the experimenters have assigned participants
> to treatment groups based on their judgment of each participant's 
> characteristics? Why or why not?
>
> > ## Solution
> > The research question asked whether exercise, specifically high-intensity
> > exercise, would affect healthspan and lifespan of elderly Norwegians. The
> > treatments were high-intensity, moderate-intensity, and national standard
> > exercise groups. The experimental units are the individuals. The responses 
> > measured were heart rate, blood pressure, strength, cognitive function and 
> > other health indicators. The main response measured was 5-year survival.
> > If participants had been allowed to choose their preferred exercise group 
> > or if experimenters had chosen the groups based on participant 
> > characteristics, extraneous variables (e.g. state of depression) could
> > be introduced into the study. When participants are randomly assigned to
> > treatment groups, these variables are spread across the groups and cancel
> > out. Furthermore, if experimenters had used their own judgment to assign
> > participants to groups, their own biases could have affected the results.
> {: .solution}
{: .challenge}


### Conducting a Comparative Experiment

Comparative experiments apply treatments to experimental units and measure the
responses, then compare the responses to those treatments with statistical
analysis. If in the Generation 100 study the experimenters had only one group
(e.g. high-intensity training), they might have achieved good results but would have no way of knowing if either of the other treatments would have achieved the same or even better results. To know whether high-intensity training is better than moderate or low-intensity training, it was necessary to run experiments in which some experimental units engaged in high-intensity training, others in moderate, and others still in low-intensity training. Only then can the 
responses to those treatments be statistically analyzed to determine treatment effects.

> ## Challenge 2: Which are the experimental units?
>
> Identify the experimental units in each experiment described below, then share
> your answers in the collaborative document.
>
> 1. Three hundred mice are individually housed in the same room. Half of them 
> are fed a high-fat diet and the other half are fed regular chow.
> 2. Three hundred mice are housed five per cage in the same room. Half of them 
> are fed a high-fat diet and the other half are fed regular chow.   
> 3. Three hundred mice are individually housed in two different rooms. Those in
> the first room are fed a high-fat diet and those in the other room are fed 
> regular chow.    
>
> > ## Solution
> > 1. The individual animal is the experimental unit.
> > 
> > 2. The cage receives the treatment and is the experimental unit.
> > 
> > 3. The room receives the treatment and is the experimental unit.
> > 
> {: .solution}
{: .challenge}

### Reducing Bias with Randomization and Blinding
Randomized studies assign experimental units to treatment groups randomly by
pulling a number out of a hat or using a computer's random number generator. The
main purpose for randomization comes later during statistical analysis, where 
we compare the data we obtained to the data distribution we might have 
obtained. Randomization provides us a way to create the distribution of data
we might have obtained and ensures that our comparisons between treatment groups
are valid. Random assignment (*allocation*) of experimental units to treatment groups prevents the subjective bias that might be introduced by an experimenter who selects, even in good faith and with good intention, which experimental 
units should get which treatment. For example, if the experimenter selected 
which people would do high-, moderate- and low-intensity training they might unconsciously bias the groups by body size or shape. This *selection bias* would influence the outcome of the experiment.

Randomization also accounts for or cancels out effects of "nuisance"
variables like the time or day of the experiment, the investigator or 
technician, equipment calibration, exposure to light or ventilation in animal rooms, or other variables that are not being studied but that do influence the responses. Randomization balances out the effects of nuisance variables between treatment groups by giving an equal probability for an experimental unit to be assigned to any treatment group.

Blinding (also known as masking) prevents the experimenter from influencing the
outcome of an experiment to suit their expectations or preferred hypothesis.
Ideally experimenters should not know which treatment the experimental units 
have received or will receive from the start to the statistical analysis stage 
of the experiment. This might require additional personnel like technicians or
other colleague to perform some tasks, and should be considered during
experimental design. If ideal circumstances can't be arranged, it should be possible to carry out at least some of the stages blind. Blinding during
allocation (assignment of experimental units to treatment groups), treatment,
data collection or data analysis can reduce experimental bias.

> ## Challenge 3: How does bias enter an experiment?
>
> Identify ways that bias enters into each experiment described below, then 
> share your answers in the collaborative document.
>
> 1. A clinician perceives increased aggression in subjects given testosterone.    
> 2. A clinician concludes that mood of each subject has improved in the 
> treatment group given a new antidepressant.    
> 3. A researcher unintentionally treats subjects differently based on their 
> treatment group by providing more food to control group animals.   
> 4. A clinician gives different nonverbal cues to patients in the treatment 
> group of a clinical trial than to the control group patients.  
>
> > ## Solution
> > 1 and 2 describe nonblind data collection reporting increased treatment
> > effects. Inflated effect sizes are a common problem with nonblinded studies.
> > In 3 and 4 the experimenter 
> > 
> {: .solution}
{: .challenge}

### Controlling Natural Variation with Blocking

Now that we've seen how to turn Fahrenheit into Celsius, it's easy to turn Celsius into Kelvin:

Randomisation within blocks  

Blocking is a method of controlling natural variation among experimental units. This splits up the experiment into smaller sub-experiments (blocks), and treatments are randomised to experimental units within each block [5,13,14]. This takes into account nuisance variables that could potentially bias the results (e.g. cage location, day or week of procedure).

Stratified randomisation uses the same principle as randomisation within blocks, only the strata tend to be traits of the animal that are likely to be associated with the response (e.g. weight class or tumour size class). This can lead to differences in the practical implementation of stratified randomisation as compared to block randomisation (e.g. there may not be equal numbers of experimental units in each weight class).

> ## Create a Function
>
> In the last lesson, we learned to **c**ombine elements into a vector using the `c` function,
> e.g. `x <- c("A", "B", "C")` creates a vector `x` with three elements.
> Furthermore, we can extend that vector again using `c`, e.g. `y <- c(x, "D")` creates a vector `y` with four elements.
> Write a function called `highlight` that takes two vectors as arguments, called
> `content` and `wrapper`, and returns a new vector that has the wrapper vector
> at the beginning and end of the content:
>
> 
> ~~~
> best_practice <- c("Write", "programs", "for", "people", "not", "computers")
> asterisk <- "***"  # R interprets a variable with a single value as a vector
>                    # with one element.
> highlight(best_practice, asterisk)
> ~~~
> {: .language-r}
> 
> 
> 
> ~~~
> [1] "***"       "Write"     "programs"  "for"       "people"    "not"      
> [7] "computers" "***"      
> ~~~
> {: .output}
>
> > ## Solution
> > ~~~
> > highlight <- function(content, wrapper) {
> >   answer <- c(wrapper, content, wrapper)
> >   return(answer)
> > }
> > ~~~
> > {: .language-r}
> {: .solution}
>
> If the variable `v` refers to a vector, then `v[1]` is the vector's first element and `v[length(v)]` is its last (the function `length` returns the number of elements in a vector).
> Write a function called `edges` that returns a vector made up of just the first and last elements of its input:
>
> 
> ~~~
> dry_principle <- c("Don't", "repeat", "yourself", "or", "others")
> edges(dry_principle)
> ~~~
> {: .language-r}
> 
> 
> 
> ~~~
> [1] "Don't"  "others"
> ~~~
> {: .output}
>
> > ## Solution
> > ~~~
> > edges <- function(v) {
> >    first <- v[1]
> >    last <- v[length(v)]
> >    answer <- c(first, last)
> >    return(answer)
> > }
> > ~~~
> > {: .language-r}
> {: .solution}
{: .challenge}

> ## The Call Stack
>
> For a deeper understanding of how functions work,
> you'll need to learn how they create their own environments and call other functions.
> Function calls are managed via the call stack.
> For more details on the call stack,
> have a look at the [supplementary material]({{ page.root }}/14-supp-call-stack/).
{: .callout}

> ## Named Variables and the Scope of Variables
>
> Functions can accept arguments explicitly assigned to a variable name in
> the function call `functionName(variable = value)`, as well as arguments by
> order:
>
> 
> ~~~
> input_1 <- 20
> mySum <- function(input_1, input_2 = 10) {
>   output <- input_1 + input_2
>   return(output)
> }
> ~~~
> {: .language-r}
>
> 1.  Given the above code was run, which value does `mySum(input_1 = 1, 3)` produce?
>     1. 4
>     2. 11
>     3. 23
>     4. 30
> 2.  If `mySum(3)` returns 13, why does `mySum(input_2 = 3)` return an error?
>
> > ## Solution
> > 1. The solution is `1.`.
> > 
> > 2. Read the error message: `argument "input_1" is missing, with no default`
> > means that no value for `input_1` is provided in the function call, 
> > and neither in the function's defintion. Thus, the addition in the
> > function body can not be completed.
> > 
> {: .solution}
{: .challenge}


### Testing, Error Handling, and Documenting

Once we start putting things in functions so that we can re-use them, we need to start testing that those functions are working correctly.
To see how to do this, let's write a function to center a dataset around a
particular midpoint:


~~~
center <- function(data, midpoint) {
  new_data <- (data - mean(data)) + midpoint
  return(new_data)
}
~~~
{: .language-r}

We could test this on our actual data, but since we don't know what the values ought to be, it will be hard to tell if the result was correct.
Instead, let's create a vector of 0s and then center that around 3.
This will make it simple to see if our function is working as expected:


~~~
z <- c(0, 0, 0, 0)
z
~~~
{: .language-r}



~~~
[1] 0 0 0 0
~~~
{: .output}



~~~
center(z, 3)
~~~
{: .language-r}



~~~
[1] 3 3 3 3
~~~
{: .output}

That looks right, so let's try center on our real data. We'll center the inflammation data from day 4 around 0:


~~~
dat <- read.csv(file = "data/inflammation-01.csv", header = FALSE)
~~~
{: .language-r}



~~~
Warning in file(file, "rt"): cannot open file 'data/inflammation-01.csv': No
such file or directory
~~~
{: .warning}



~~~
Error in file(file, "rt"): cannot open the connection
~~~
{: .error}



~~~
centered <- center(dat[, 4], 0)
~~~
{: .language-r}



~~~
Error in center(dat[, 4], 0): object 'dat' not found
~~~
{: .error}



~~~
head(centered)
~~~
{: .language-r}



~~~
Error in head(centered): object 'centered' not found
~~~
{: .error}

It's hard to tell from the default output whether the result is correct, but there are a few simple tests that will reassure us:


~~~
# original mean
mean(dat[, 4])
~~~
{: .language-r}



~~~
Error in mean(dat[, 4]): object 'dat' not found
~~~
{: .error}



~~~
# centered mean
mean(centered)
~~~
{: .language-r}



~~~
Error in mean(centered): object 'centered' not found
~~~
{: .error}











































