---
title: "Statistics in Data Analysis"
teaching: 0
exercises: 0
questions:
- "How can information be extracted and communicated from experimental data?"
objectives:
- "Plotting reveals information in the data."
- "Statistical significance testing compares experimental data obtained to probability distributions of data that might also be possible."
- "A probability distribution is a mathematical function that gives the probabilities of different possible outcomes for an experiment."
keypoints:
- "Plotting and significance testing describe patterns in the data and quantify effects against random variation."
source: Rmd
---

```{r, include = FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("03-")
```

## A picture is worth a thousand words

To motivate this next section on statistics, we start with an example of human
variability. This 1975 living histogram of female students from the University 
of Wisconsin Madison shows variability in a natural population.

![living histogram of female student heights](../fig/joiner-living-histogram-heights.png)

[B. Joiner, Int'l Stats Review, 1975](https://personal.psu.edu/drh20/talks/joiner_living_histograms.pdf)

> ## Exercise 1: A living histogram
> From the living histogram, can you estimate by eye  
> 1). the mean and median heights of this sample of female students?  
> 2). the spread of the data? Estimate either standard deviation or variance by
> eye. If you're not sure how to do this, think about how you would describe the
> spread of the data from the mean. You do not need to calculate a statistic.  
> 3). any outliers? Estimate by eye - don't worry about calculations.  
> 4). What do you predict would happen to mean, median, spread and outliers if
> an equal number of male students were added to the histogram?
>
> >
> > ## Solution to Exercise 1
> > 
> > 1). Mean and median are two measures of the center of the data. The median
> > is the 50th% of the data with half the female students above this value and
> > the other half below. There are approximately 100 students total. Fifty of
> > them appear to be above 5 feet 5 inches and fifty of them appear to be below
> > 5'5". The median is not influenced by extreme values (outliers), but the 
> > mean value is. While there are some very tall and very short people, the
> > bulk of them appear to be centered around a mean of 5 foot 5 inches with
> > a somewhat longer right tail to the histogram.  
> > 2). If the mean is approximately 5'5" and the distribution appears normal
> > (bell-shaped), then we know that approximately 68% of the data lies within
> > one standard deviation (sd) of the mean and ~95% lies within two sd's. If 
> > there are ~100 people in the sample, 95% of them lie between 5'0" and 5'10"
> > (2 sd's = 5" above and 5" below the mean). One standard deviation then would > > be about 5"/2 = 2.5" from the mean of 5'5". So 68% of the data (~68 people) > > lie within 5 feet 2.5 inches and 5 feet 7.5 inches.  
> > 3). There are some very tall and very short people but it's not clear 
> > whether they are outliers. Outliers deviate significantly from expected 
> > values, specifically by more than 3 standard deviations in a normal
> > distribution. Values that are greater than 3 sd's (7.5") above or below the
> > mean could be considered outliers. Outliers would then be shorter than 4
> > feet 7.5 inches or taller than 6 feet 2.5 inches. The shortest are 4 feet 9
> > inches and the tallest 6' 0 inches. There are no outliers in this sample 
> > because all heights fall within 3 sd's.
> > 4). Average male heights are greater than average female heights, so you 
> > could expect that a random sample of 100 male students would increase the
> > average height of the sample of 200 students. The mean would shift to the
> > right of the distribution toward taller heights, as would the median. 
> > 
> {: .solution}
{: .challenge} 

## The first step in data analysis: plot the data!
A picture is worth a thousand words, and a picture of your data could reveal
important information that can guide you forward. So first, plot the data!

```{r, simulate_gen100_data}
# simulate Generation 100 resting heart rate data for the 1,567 study 
# participants
# rnorm() generates a random normal distribution from the mean and standard
# deviation values you provide
simulated_heart_rates <- rnorm(n = 1567, mean = 80, sd = 10)

# take a sample of 100 and create a histogram
# first set the seed for the random number generator
set.seed(42)
sample100 <- sample(simulated_heart_rates, 100)
hist(sample100, xlab = "resting heart rate for 100 participants")
```

> ## Exercise 2: What does this picture tell you about resting heart rates?  
> Do the data appear to be normally distributed? Why does this matter?  
> Do the left and right tails of the data seem to mirror each other or not?  
> Are there gaps in the data?  
> Are there large clusters of similar heart rate values in the data?  
> Are there apparent outliers?  
> What message do the data deliver in this histogram?  
> >
> > ## Solution to Exercise 2
> > 
> > 
> > 
> {: .solution}
{: .challenge}

Now create a boxplot of the same sample data.

```{r, boxplot_simulated_gen100_data}
boxplot(sample100)
```

> ## Exercise 3: What does this boxplot tell you about resting heart rates?  
> What does the box signify?  
> What does horizontal black line dividing the box signify?  
> Are there apparent outliers?  
> How does the boxplot relate to the histogram?
> What message do the data deliver in this boxplot?  
> >
> > ## Solution to Exercise 3
> > 
> > 
> > 
> {: .solution}
{: .challenge}

Plotting the data can reveal relationships between variables, identify unusual 
response measurements (**outliers**) and guide further statistical analysis.
When data are not normally distributed (bell-shaped and symmetrical), many of 
the statistical methods typically used will not perform well. In these cases
the data can be transformed to a more symmetrical bell-shaped curve.

## Statistical significance testing
The Generation 100 studied aims to determine whether high-intensity exercise in
elderly adults affects lifespan and healthspan. A substudy looked at whether
cardiorespiratory fitness, the supply of oxygen to skeletal muscles, is linked 
to high blood volume in the elderly. It is well known that physical activity can increase blood volume and that high blood volume is crucial to athletic 
performance, however, this is the first study to demonstrate this relationship 
in elderly people.

To test whether exercise affects blood volume, 50 volunteers from the Generation 
100 participants were [placed in two groups](https://frontiersin.org/articles/10.3389/fspor.2021.638139/full) 
- fit or unfit - depending on results of peak oxygen uptake testing. Exercise
was objectively measured with a wearable sensor for one week between peak 
oxygen testing and blood volume measurements. Simulated data are shown below.

```{r, simulate_BV_data, include=FALSE}
# simulate blood volume data
blood_volume <- as.data.frame(matrix(rnorm(n = 25, mean = 5, sd = 1), 
                                     nrow = 25))
blood_volume <- rbind(blood_volume, 
                      as.data.frame(matrix(rnorm(n = 25, mean = 4, sd = 1), 
                                           nrow = 25)))
fitness <- rep(c("fit", "unfit"), each = 25) 
blood_volume <- cbind(blood_volume, fitness)
names(blood_volume) <- c("blood_volume", "CR_fitness")
write.csv(blood_volume, file = "../data/blood_volume.csv")
```

```{r, simulate_BV_boxplot}
boxplot(blood_volume ~ fitness, data = blood_volume)
```

> ## Exercise 3: Comparing two groups
> Does there appear to be a significant blood volume difference between the 
> two groups? How would you know?   
> Do any of the data overlap between the two boxplots?  
> >
> > ## Solution to Exercise 3
> > 
> > 
> > 
> {: .solution}
{: .challenge}

## The t-test
What does it mean that a difference is statistically significant? We can eye
plots like the one above and see a difference, however, we need something more 
objective than eyeballs to claim a significant difference. 

```{r, t_test}
# read in the simulated blood volume data
blood_volume <- read.csv("../data/blood_volume.csv")
CR_fit <- blood_volume[blood_volume$CR_fitness == "fit", "blood_volume"]
CR_unfit <- blood_volume[blood_volume$CR_fitness == "unfit", "blood_volume"]

t.test(x=CR_fit, y=CR_unfit)
```
The t-test, a test of statistical significance, indicates that fit people had a
mean blood volume significantly greater than unfit people. Note: these are 
simulated data, not real data from the study.

## Probability and probability distributions
Suppose you have measured the resting heart rate of the entire population of 
people who are 70 or older, not just the 1,567 from the Generation 100 study. 
Imagine you need to describe these numbers to someone who has no idea what 
resting heart rate is. Suppose all the measurements are contained in 
`simulated_heart_rates`. We could list out all of the numbers for them to see or 
take a sample and show them the sample, but this would be inefficient and 
wouldn't provide much insight into the data. A better approach is to define and 
visualize a **distribution**. The simplest way to think of a distribution is as 
a compact description of many numbers. 

Histograms show us the proportion of values within an interval. Here is a 
histogram showing all resting heart rates.

```{r, simulate_population_hist, include=FALSE}
hist(simulated_heart_rates, xlab = "resting heart rate")
```

Showing this plot is much more informative and easier to interpret than a long
table of numbers. With this histogram we can approximate the number of 
individuals in any given interval. For example, there are approximately
30 individuals (~2%) with a resting heart rate greater than 100. The 
probability distribution we see above approximates one that is very common in 
nature: the bell curve, also known as the **normal distribution** or Gaussian
distribution.

```{r, standard_normal_dist, include=FALSE}
plot(function(x) dnorm(x), -3.5, 3.5, main = "Standard normal distribution", 
     xlab = "z", ylab = "")
```

The curve shown above is an example of a **probability density function** that
defines a bell-shaped curve. The y-axis is the **probability density**. 
Statistical convention denotes a variable that has a standard normal 
distribution by *z*. The total area under the curve sums to 1.0. If you draw a
random value from a normal distribution, the probability that the value falls in
a particular interval, say from a to b, is given by the area under the curve
between a and b. Software can be used to calculate these probabilities.

When the histogram of a list of numbers approximates the normal distribution, 
we can use a convenient mathematical formula to approximate the proportion of 
values or outcomes in any given interval. Real-world populations may be 
approximated by the mathematical ideal of the normal distribution. Repeat the
sampling we did earlier and produce a new histogram of the sample.

```{r, sample_hist}
sample100 <- sample(simulated_heart_rates, 100)
hist(sample100, xlab = "resting heart rate for 100 participants")
```

> ## Exercise 4: Sampling from a population
> Does the sample appear to be normally distributed?   
> Can you estimate the mean resting heart rate by eye?  
> What is the sample mean using R?  
> Can you estimate the sample standard deviation by eye? Hint: if normally 
> distributed, 68% of the data will lie within one standard deviation of the 
> mean and 95% will lie within 2 standard deviations.
> What is the sample standard deviation using R?  
> What message does the sample deliver about the population from which it was
> drawn?  
> >
> > ## Solution to Exercise 4
> > 
> > 
> > 
> {: .solution}
{: .challenge}

## The perils of p-values

## Confidence intervals

## Sample sizes and power curves

## Comparing standard deviations


{% include links.md %}